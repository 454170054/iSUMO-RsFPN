{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from code.models.RsFPN import Res_FPN\n",
    "import pandas as pd\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:52:02.909394Z",
     "iopub.execute_input": "2023-08-16T08:52:02.909762Z",
     "iopub.status.idle": "2023-08-16T08:52:11.798622Z",
     "shell.execute_reply.started": "2023-08-16T08:52:02.909730Z",
     "shell.execute_reply": "2023-08-16T08:52:11.797593Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the prediction\n",
    "def save_predict_result(data, output):\n",
    "    with open(output, 'w') as f:\n",
    "        if len(data) > 1:\n",
    "            for i in range(len(data)):\n",
    "                f.write('# result for fold %d\\n' % (i + 1))\n",
    "                for j in range(len(data[i])):\n",
    "                    f.write('%d\\t%s\\n' % (data[i][j][0], data[i][j][2]))\n",
    "        else:\n",
    "            for i in range(len(data)):\n",
    "                f.write('# result for predict\\n')\n",
    "                for j in range(len(data[i])):\n",
    "                    f.write('%d\\t%s\\n' % (data[i][j][0], data[i][j][2]))\n",
    "        f.close()\n",
    "    return None\n",
    "\n",
    "\n",
    "# Plot the ROC curve and return the AUC value\n",
    "def plot_roc_curve(data, output, label_column=0, score_column=2):\n",
    "    datasize = len(data)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    fprArray = []\n",
    "    tprArray = []\n",
    "    thresholdsArray = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    for i in range(len(data)):\n",
    "        fpr, tpr, thresholds = roc_curve(data[i][:, label_column], data[i][:, score_column])\n",
    "        fprArray.append(fpr)\n",
    "        tprArray.append(tpr)\n",
    "        thresholdsArray.append(thresholds)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blueviolet', 'deeppink'])\n",
    "    plt.figure(figsize=(7, 7), dpi=300)\n",
    "    for i, color in zip(range(len(fprArray)), colors):\n",
    "        if datasize > 1:\n",
    "            plt.plot(fprArray[i], tprArray[i], lw=1, alpha=0.7, color=color,\n",
    "                     label='ROC fold %d (AUC = %0.4f)' % (i + 1, aucs[i]))\n",
    "        else:\n",
    "            plt.plot(fprArray[i], tprArray[i], lw=1, alpha=0.7, color=color,\n",
    "                     label='ROC (AUC = %0.4f)' % aucs[i])\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Random', alpha=.8)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    # Calculate the standard deviation\n",
    "    std_auc = np.std(aucs)\n",
    "    if datasize > 1:\n",
    "        plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "                 label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.9)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    if datasize > 1:\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(output)\n",
    "    plt.close(0)\n",
    "    return mean_auc, aucs\n",
    "\n",
    "\n",
    "# Calculate and save performance metrics\n",
    "def calculate_metrics(labels, scores, cutoff=0.5, po_label=1):\n",
    "    my_metrics = {\n",
    "        'SN': 'NA',\n",
    "        'SP': 'NA',\n",
    "        'ACC': 'NA',\n",
    "        'MCC': 'NA',\n",
    "        'Recall': 'NA',\n",
    "        'Precision': 'NA',\n",
    "        'F1-score': 'NA',\n",
    "        'Cutoff': cutoff,\n",
    "    }\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(scores)):\n",
    "        if labels[i] == po_label:\n",
    "            if scores[i] >= cutoff:\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if scores[i] < cutoff:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "\n",
    "    my_metrics['SN'] = tp / (tp + fn) if (tp + fn) != 0 else 'NA'\n",
    "    my_metrics['SP'] = tn / (fp + tn) if (fp + tn) != 0 else 'NA'\n",
    "    my_metrics['ACC'] = (tp + tn) / (tp + fn + tn + fp)\n",
    "    my_metrics['MCC'] = (tp * tn - fp * fn) / np.math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) \\\n",
    "        if (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) != 0 else 'NA'\n",
    "    my_metrics['Precision'] = tp / (tp + fp) if (tp + fp) != 0 else 'NA'\n",
    "    my_metrics['Recall'] = my_metrics['SN']\n",
    "    my_metrics['F1-score'] = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 'NA'\n",
    "    return my_metrics\n",
    "\n",
    "\n",
    "def calculate_metrics_list(data, label_column=0, score_column=2, cutoff=0.5, po_label=1):\n",
    "    metrics_list = []\n",
    "    for i in data:\n",
    "        metrics_list.append(calculate_metrics(i[:, label_column], i[:, score_column], cutoff=cutoff, po_label=po_label))\n",
    "    if len(metrics_list) == 1:\n",
    "        return metrics_list\n",
    "    else:\n",
    "        mean_dict = {}\n",
    "        std_dict = {}\n",
    "        keys = metrics_list[0].keys()\n",
    "        for i in keys:\n",
    "            mean_list = []\n",
    "            for metric in metrics_list:\n",
    "                mean_list.append(metric[i])\n",
    "            mean_dict[i] = np.array(mean_list).sum() / len(metrics_list)\n",
    "            std_dict[i] = np.array(mean_list).std()\n",
    "        metrics_list.append(mean_dict)\n",
    "        metrics_list.append(std_dict)\n",
    "        return metrics_list\n",
    "\n",
    "\n",
    "def save_prediction_metrics_list(metrics_list, output):\n",
    "    if len(metrics_list) == 1:\n",
    "        with open(output, 'w') as f:\n",
    "            f.write('Result')\n",
    "            for keys in metrics_list[0]:\n",
    "                f.write('\\t%s' % keys)\n",
    "            f.write('\\n')\n",
    "            for i in range(len(metrics_list)):\n",
    "                f.write('value')\n",
    "                for keys in metrics_list[i]:\n",
    "                    f.write('\\t%s' % metrics_list[i][keys])\n",
    "                f.write('\\n')\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(output, 'w') as f:\n",
    "            f.write('Fold')\n",
    "            for keys in metrics_list[0]:\n",
    "                f.write('\\t%s' % keys)\n",
    "            f.write('\\n')\n",
    "            for i in range(len(metrics_list)):\n",
    "                if i <= len(metrics_list) - 3:\n",
    "                    f.write('%d' % (i + 1))\n",
    "                elif i == len(metrics_list) - 2:\n",
    "                    f.write('mean')\n",
    "                else:\n",
    "                    f.write('std')\n",
    "                for keys in metrics_list[i]:\n",
    "                    f.write('\\t%s' % metrics_list[i][keys])\n",
    "                f.write('\\n')\n",
    "            f.close()\n",
    "    return None\n",
    "\n",
    "\n",
    "# Fixed SP value, computing performance\n",
    "def fixed_sp_calculate_metrics_list(data, cutoffs, label_column=0, score_column=1, po_label=1):\n",
    "    metrics_list = []\n",
    "    for index, i in enumerate(data):\n",
    "        metrics_list.append(\n",
    "            calculate_metrics(i[:, label_column], i[:, score_column], cutoff=cutoffs[index], po_label=po_label))\n",
    "    if len(metrics_list) == 1:\n",
    "        return metrics_list\n",
    "    else:\n",
    "        mean_dict = {}\n",
    "        std_dict = {}\n",
    "        keys = metrics_list[0].keys()\n",
    "        for i in keys:\n",
    "            mean_list = []\n",
    "            for metric in metrics_list:\n",
    "                mean_list.append(metric[i])\n",
    "            mean_dict[i] = np.array(mean_list).sum() / len(metrics_list)\n",
    "            std_dict[i] = np.array(mean_list).std()\n",
    "        metrics_list.append(mean_dict)\n",
    "        metrics_list.append(std_dict)\n",
    "        return metrics_list\n",
    "\n",
    "\n",
    "def save_result(cv_res, ind_res, outPath, codename):\n",
    "    out = os.path.join(outPath, codename.lower())\n",
    "    save_predict_result(cv_res, out + '_pre_cv.txt')\n",
    "    cv_meanauc, cv_auc = plot_roc_curve(cv_res, out + '_roc_cv.png', label_column=0, score_column=2)\n",
    "    cv_metrics = calculate_metrics_list(cv_res, label_column=0, score_column=2, cutoff=0.5, po_label=1)\n",
    "    save_prediction_metrics_list(cv_metrics, out + '_metrics_cv.txt')\n",
    "\n",
    "    if ind_res is not None:\n",
    "        save_predict_result(ind_res, out + '_pre_ind.txt')\n",
    "        ind_meanauc, ind_auc = plot_roc_curve(ind_res, out + '_roc_ind.png', label_column=0, score_column=2)\n",
    "        ind_metrics = calculate_metrics_list(ind_res, label_column=0, score_column=2, cutoff=0.5, po_label=1)\n",
    "        save_prediction_metrics_list(ind_metrics, out + '_metrics_ind.txt')\n",
    "\n",
    "\n",
    "# Create folder\n",
    "def mkdir(path):\n",
    "    path = path.strip()\n",
    "    path = path.rstrip(\"\\\\\")\n",
    "    # Check if the path exists\n",
    "    isExists = os.path.exists(path)\n",
    "    if not isExists:\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        # Do not create directory if it exists\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "parent_dir = os.path.abspath(os.path.dirname(os.getcwd()))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:52:11.853359Z",
     "iopub.execute_input": "2023-08-16T08:52:11.853904Z",
     "iopub.status.idle": "2023-08-16T08:52:11.865094Z",
     "shell.execute_reply.started": "2023-08-16T08:52:11.853871Z",
     "shell.execute_reply": "2023-08-16T08:52:11.864252Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainfilepath = r'../../dataset/five_fold_cross_validation.csv'\n",
    "testfilepath = r'../../dataset/independent.csv'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:52:11.866186Z",
     "iopub.execute_input": "2023-08-16T08:52:11.867616Z",
     "iopub.status.idle": "2023-08-16T08:52:11.879052Z",
     "shell.execute_reply.started": "2023-08-16T08:52:11.867583Z",
     "shell.execute_reply": "2023-08-16T08:52:11.878121Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load AAF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from code.feature_extraction.aaindex import AAIndex\n",
    "aaindex_train = AAIndex(trainfilepath)\n",
    "aaindex_test = AAIndex(testfilepath)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:52:11.880495Z",
     "iopub.execute_input": "2023-08-16T08:52:11.880825Z",
     "iopub.status.idle": "2023-08-16T08:54:24.307747Z",
     "shell.execute_reply.started": "2023-08-16T08:52:11.880794Z",
     "shell.execute_reply": "2023-08-16T08:54:24.306699Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load ZSF and labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from code.feature_extraction.zsf import ZScale\n",
    "zscale_train, y = ZScale(trainfilepath, 1)\n",
    "zscale_test, y_test = ZScale(testfilepath, 1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:54:24.309109Z",
     "iopub.execute_input": "2023-08-16T08:54:24.310099Z",
     "iopub.status.idle": "2023-08-16T08:54:32.219440Z",
     "shell.execute_reply.started": "2023-08-16T08:54:24.310061Z",
     "shell.execute_reply": "2023-08-16T08:54:32.218408Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load PBF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from code.feature_extraction.pbf import extract_embedding_features\n",
    "train_seqs = pd.read_csv(trainfilepath, sep=',')['Sequence']\n",
    "protein_bert_train = extract_embedding_features(train_seqs.values.tolist())\n",
    "protein_bert_train = np.float32(protein_bert_train)\n",
    "\n",
    "test_seqs = pd.read_csv(testfilepath, sep=',')['Sequence']\n",
    "protein_bert_test = extract_embedding_features(test_seqs.values.tolist())\n",
    "protein_bert_test = np.float32(protein_bert_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:54:32.220886Z",
     "iopub.execute_input": "2023-08-16T08:54:32.221235Z",
     "iopub.status.idle": "2023-08-16T08:55:13.033331Z",
     "shell.execute_reply.started": "2023-08-16T08:54:32.221200Z",
     "shell.execute_reply": "2023-08-16T08:55:13.032310Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# experimental results of 5-fload cross validation and independent test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    suboutput = os.path.join(parent_dir, 'Results')\n",
    "    mkdir(suboutput)\n",
    "    prediction_result_cv = []\n",
    "    prediction_result_ind = []\n",
    "    file_Name = 'iSumo-RsFPN'\n",
    "    folds = StratifiedKFold(5).split(zscale_train, y)\n",
    "    historys = []\n",
    "    for i, (train, valid) in tqdm(enumerate(folds)):\n",
    "        train_x_emb, train_y = protein_bert_train[train], y[train]\n",
    "        valid_x_emb, valid_y = protein_bert_train[valid], y[valid]\n",
    "        train_x_zscale, valid_x_zscale = zscale_train[train], zscale_train[valid]\n",
    "        train_x_aaindex, valid_x_aaindex = aaindex_train[train], aaindex_train[valid]\n",
    "        modelName = 'model1' + str(i + 1) + '.h5'\n",
    "        filepath_1 = os.path.join(suboutput, modelName)\n",
    "        network_1 = Res_FPN(train_x_emb)\n",
    "        early_stopping_1 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=50)\n",
    "        best_saving_1 = tf.keras.callbacks.ModelCheckpoint(filepath_1, monitor='val_acc', mode='auto',\n",
    "                                                           verbose=0, save_best_only=True, save_weights_only=True)\n",
    "        network_1.fit(train_x_emb, train_y, validation_data=(valid_x_emb, valid_y), epochs=1000, batch_size=128,\n",
    "                      shuffle=True, callbacks=[best_saving_1, early_stopping_1], verbose=0)\n",
    "        network_1.load_weights(filepath_1)\n",
    "        p1, p2, p3 = network_1.predict(valid_x_emb)\n",
    "        p_1 = (p1 + p2 + p3) / 3\n",
    "\n",
    "        modelName = 'model2' + str(i + 1) + '.h5'\n",
    "        filepath_2 = os.path.join(suboutput, modelName)\n",
    "        network_2 = Res_FPN(train_x_zscale)\n",
    "        early_stopping_2 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=50)\n",
    "        best_saving_2 = tf.keras.callbacks.ModelCheckpoint(filepath_2, monitor='val_acc', mode='auto',\n",
    "                                                           verbose=0, save_best_only=True, save_weights_only=True)\n",
    "        network_2.fit(train_x_zscale, train_y, validation_data=(valid_x_zscale, valid_y), epochs=1000, batch_size=128,\n",
    "                      shuffle=True, callbacks=[best_saving_2, early_stopping_2], verbose=0)\n",
    "        network_2.load_weights(filepath_2)\n",
    "        p1, p2, p3 = network_2.predict(valid_x_zscale)\n",
    "        p_2 = (p1 + p2 + p3) / 3\n",
    "\n",
    "        modelName = 'model3' + str(i + 1) + '.h5'\n",
    "        filepath_3 = os.path.join(suboutput, modelName)\n",
    "        network_3 = Res_FPN(train_x_aaindex)\n",
    "        early_stopping_3 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=50)\n",
    "        best_saving_3 = tf.keras.callbacks.ModelCheckpoint(filepath_3, monitor='val_acc', mode='auto',\n",
    "                                                           verbose=0, save_best_only=True, save_weights_only=True)\n",
    "        network_3.fit(train_x_aaindex, train_y, validation_data=(valid_x_aaindex, valid_y), epochs=1000, batch_size=128,\n",
    "                      shuffle=True, callbacks=[best_saving_3, early_stopping_3], verbose=0)\n",
    "        network_3.load_weights(filepath_3)\n",
    "        p1, p2, p3 = network_3.predict(valid_x_aaindex)\n",
    "        p_3 = (p1 + p2 + p3) / 3\n",
    "\n",
    "        p = (p_1 + p_2 + p_3) / 3\n",
    "\n",
    "        tmp_result = np.zeros((len(valid_y), 3))\n",
    "        tmp_result[:, 0], tmp_result[:, 1:] = valid_y, p\n",
    "        prediction_result_cv.append(tmp_result)\n",
    "\n",
    "        tmp_result1 = np.zeros((len(y_test), 3))\n",
    "        p1, p2, p3 = network_1.predict(protein_bert_test)\n",
    "        p_1 = (p1 + p2 + p3) / 3\n",
    "        p1, p2, p3 = network_2.predict(zscale_test)\n",
    "        p_2 = (p1 + p2 + p3) / 3\n",
    "        p1, p2, p3 = network_3.predict(aaindex_test)\n",
    "        p_3 = (p1 + p2 + p3) / 3\n",
    "        p = (p_1 + p_2 + p_3) / 3\n",
    "        tmp_result1[:, 0], tmp_result1[:, 1:] = y_test, p\n",
    "        prediction_result_ind.append(tmp_result1)\n",
    "    save_result(prediction_result_cv, prediction_result_ind, suboutput, file_Name)\n",
    "\n",
    "    return historys"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:55:13.058173Z",
     "iopub.execute_input": "2023-08-16T08:55:13.058534Z",
     "iopub.status.idle": "2023-08-16T08:55:13.081785Z",
     "shell.execute_reply.started": "2023-08-16T08:55:13.058498Z",
     "shell.execute_reply": "2023-08-16T08:55:13.080793Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "flag = train()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T08:55:13.083047Z",
     "iopub.execute_input": "2023-08-16T08:55:13.083560Z",
     "iopub.status.idle": "2023-08-16T08:59:12.501049Z",
     "shell.execute_reply.started": "2023-08-16T08:55:13.083525Z",
     "shell.execute_reply": "2023-08-16T08:59:12.497972Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}